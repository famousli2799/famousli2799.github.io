<?xml version="1.0" encoding="utf-8"?>


<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN">
    <title type="text">李清华的博客</title>
    <subtitle type="html">李清华的博客</subtitle>
    <updated>2023-06-17T19:50:24&#43;08:00</updated>
    <id>https://famousli.cn/</id>
    <link rel="alternate" type="text/html" href="https://famousli.cn/" />
    <link rel="self" type="application/atom&#43;xml" href="https://famousli.cn/atom.xml" />
    <author>
            <name>李清华</name>
            <uri>https://famousli.cn/</uri>
            
                <email>famousli2799@gmail.com</email>
            </author>
    
    <generator uri="https://gohugo.io/" version="0.113.0">Hugo</generator>
        <entry>
            <title type="text">计算卸载|论文阅读笔记（二）</title>
            <link rel="alternate" type="text/html" href="https://famousli.cn/notes/mecnote2/" />
            <id>https://famousli.cn/notes/mecnote2/</id>
            <updated>2023-06-17T19:26:30&#43;08:00</updated>
            <published>2023-06-17T19:04:14&#43;08:00</published>
            <author>
                    <name>李清华</name>
                    <uri>https://famousli.cn/</uri>
                    <email>famousli2799@gmail.com</email>
                    </author>
            <summary type="html">标题：Deep Reinforcement Learning for Online Offloading in Wireless Powered Mobile-Edge Computing Networks（无线供电移动边缘计算网络中在线卸……</summary>
            
                <content type="html">&lt;p&gt;标题：Deep Reinforcement Learning for Online Offloading in Wireless Powered Mobile-Edge Computing Networks（无线供电移动边缘计算网络中在线卸载的深度强化学习）&lt;/p&gt;
&lt;p&gt;年份：2020&lt;/p&gt;
&lt;p&gt;期刊：IEEE Transactions on Mobile Computing&lt;/p&gt;
&lt;p&gt;摘要：提出了一种基于深度强化学习的在线卸载 (DROO) 框架，该框架实现了一个深度神经网络来生成卸载决策。避免了一些现有强化学习方法遇到的维度灾难问题，并且在大型网络中计算效率高。为了进一步降低计算复杂度，我们提出了一种自适应程序，可以动态自动调整 DROO 算法的参数。数值结果表明，与现有方法相比，所提出的算法可以实现接近最优的性能，同时将计算时间显着减少一个数量级以上。例如，在 30 个用户的网络中，复杂度从几秒减少到不到 0.1 秒，即使在快速衰落的环境中，实时和优化的卸载设计也真正可行。&lt;/p&gt;
&lt;h2 id=&#34;主要贡献&#34;&gt;主要贡献&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提出了一种基于深度强化学习的在线卸载算法 DROO，DROO算法完全消除了解决复杂混合整数规划问题的需要，从而避免了现有优化和启发式方法遇到的最优效率权衡。&lt;/li&gt;
&lt;li&gt;设计了保序量化和自适应参数设置方法以实现快速算法收敛。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;系统模型&#34;&gt;系统模型&lt;/h2&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230505190402304.png&#34; alt=&#34;image-20230505190402304&#34; style=&#34;zoom: 33%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;无线供电MEC网络由1个AP（access point）和N个WD（wireless devices）组成。&lt;/li&gt;
&lt;li&gt;AP供电稳定，可以向WD广播射频能量。&lt;/li&gt;
&lt;li&gt;每个 WD 都有一个可充电电池，可以存储收集的能量，为设备的运行提供动力。&lt;/li&gt;
&lt;li&gt;假定 AP 具有比 WD 更高的计算能力，以便 WD 可以将其计算任务卸载到 AP。&lt;/li&gt;
&lt;li&gt;假设 WPT （wireless power transfer）和通信（计算卸载）在同一频带中执行。&lt;/li&gt;
&lt;li&gt;在每个设备处实施时分复用（TDD）电路以避免WPT和通信之间的相互干扰。&lt;/li&gt;
&lt;li&gt;h~i~ 表示标记时间帧中 AP 和第 i 个 WD 之间的无线信道增益。&lt;/li&gt;
&lt;li&gt;二进制卸载，x~i~ ∈ {0, 1} 为指示变量，其中 x~i~ = 1 表示第 i 个用户的计算任务被卸载到 AP（如图WD1和WD3），x~i~ = 0 表示任务在本地计算（如图WD2）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题表述&#34;&gt;问题表述&lt;/h2&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230506213341358.png&#34; alt=&#34;image-20230506213341358&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;$Q(h,x,\tau ,\alpha )$：无线供电的 MEC 网络的加权和计算速率&lt;/p&gt;
&lt;p&gt;$\tau _i$：表示为第 i 个 WD 的卸载时间，$\tau _i$∈ [0, 1]&lt;/p&gt;
&lt;p&gt;$\alpha$：在时间帧的开始，$\alpha$T 时间量用于 WPT，$\alpha$ ∈ [0, 1]&lt;/p&gt;
&lt;p&gt;问题（P1）：对于具有通道实现 h 的每个时间帧，求最大化加权和计算速率&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230506213035889.png&#34; alt=&#34;image-20230506213035889&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;问题(P1)是混合整数规划非凸问题，求解难度大。如果给定 x，(P1) 就简化为如下凸问题：&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230506215039239.png&#34; alt=&#34;image-20230506215039239&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;问题（P1）可以分解为两个子问题：卸载决策和资源分配（P2）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;卸载决策：需要在 2N 个可能的卸载决策中搜索以找到最优或次优卸载决策 x&lt;/p&gt;
&lt;p&gt;本文中提出了一种基于深度强化学习的在线卸载（DROO）算法。DROO 算法可以在信道分布发生变化时自动更新其卸载决策策略，并且可以在解决卸载决策问题时实现毫秒级的计算时间，更适合动态无线应用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源分配：可以有效地解决凸问题 (P2) 的最佳时间分配 {$\alpha$*, $\tau _i$ *}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;droo-算法&#34;&gt;DROO 算法&lt;/h2&gt;
&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;
&lt;p&gt;基于深度强化学习的在线卸载算法 DROO，旨在具有二进制计算卸载的无线供电 MEC 网络中最大化加权和计算率。该算法不需要任何手动标记的训练数据，并从过去的卸载经验中学习，以通过强化学习改进 DNN 产生的卸载动作。与传统的优化方法相比，所提出的 DROO 算法完全消除了解决复杂混合整数规划问题的需要。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507152152641.png&#34; alt=&#34;image-20230507152152641&#34;&gt;&lt;/p&gt;
&lt;p&gt;DROO 算法由两个交替阶段组成：卸载动作生成和卸载策略更新。&lt;/p&gt;
&lt;h3 id=&#34;droo算法&#34;&gt;DROO算法&lt;/h3&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507164155763.png&#34; alt=&#34;image-20230507164155763&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;h3 id=&#34;k的自适应设置&#34;&gt;K的自适应设置&lt;/h3&gt;
&lt;p&gt;DROO 算法的主要计算复杂度来自于在每个时间帧中求解 (P2) K 次以选择最佳卸载动作。较大的 K 通常会导致在每个时间范围内做出更好的卸载决策，并相应地在长期内产生更好的卸载策略。因此，在设置 K 的值时存在基本的性能-复杂性权衡。&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507170826786.png&#34; alt=&#34;image-20230507170826786&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;K~t~ 表示为量化函数在第 t 个时间帧生成的二进制卸载动作的数量，并设置 K~1~ = N，每隔 Δ 时间帧更新 K~t~，其中 Δ 称为 K 的更新间隔。在更新时间帧上，K~t~ 设置为 1 加上过去 Δ 时间帧中观察到的最大 k~t~^*^ 。对于 ∆ = 1 的极端情况，K~t~ 在每个时间帧中更新。当 ∆ → ∞ 时，K~t~ 不再更新，相当于设置一个常数 K = N。&lt;/p&gt;
&lt;h3 id=&#34;dnn&#34;&gt;DNN&lt;/h3&gt;
&lt;p&gt;在所提出的 DROO 算法中，由一个输入层、两个隐藏层和一个输出层组成DNN，其中第一和第二隐藏层分别具有 120 和 80 个隐藏神经元，并设置训练间隔 δ = 10，训练批量大小 batch size  = 128，内存大小为 1024。&lt;/p&gt;
&lt;h2 id=&#34;实验结果分析&#34;&gt;实验结果分析&lt;/h2&gt;
&lt;h3 id=&#34;收敛性能&#34;&gt;收敛性能&lt;/h3&gt;
&lt;p&gt;归一化计算率 $\hat{Q} (h,x)$ ∈ [0, 1] 定义为：&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507173856994.png&#34; alt=&#34;image-20230507173856994&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;其中分母中的最优解是通过枚举所有 2N 卸载动作获得的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507180855332.png&#34; alt=&#34;image-20230507180855332&#34;&gt;&lt;/p&gt;
&lt;p&gt;蓝色曲线表示最近 50 个时间帧中$\hat{Q}$的移动平均值，浅蓝色阴影表示最近 50 帧中$\hat{Q}$的最大值和最小值。当 t 很大时，DROO 的移动平均值$\hat{Q}$逐渐收敛到最优解。在 t &amp;gt; 400 的早期阶段，达到的平均值$\hat{Q}$超过 0.98，并且随着 t 变大，例如当 t &amp;gt; 3000 时，方差逐渐减小到零。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507180833497.png&#34; alt=&#34;image-20230507180833497&#34;&gt;&lt;/p&gt;
&lt;p&gt;比较了两种量化方法的性能：所提出的保序量化方法和传统的 KNN 量化方法在不同的 K 下。&lt;/p&gt;
&lt;p&gt;当 K = N 时，两种方法都收敛于最优卸载动作，即$\hat{Q}$的移动平均值接近 1。但是，当 K 较小时，它们都实现了次优卸载动作。例如，当 K = 2 时，保序量化方法和 KNN 都只能收敛到 0.95 左右。&lt;/p&gt;
&lt;p&gt;当 K ≥ 2 时，保序量化方法比 KNN 方法收敛得更快。直观上，这是因为保序量化方法比 KNN 方法在候选动作中提供了更大的多样性。因此，DNN 的训练需要在收敛前探索较少的卸载动作。&lt;/p&gt;
&lt;p&gt;当 K = 1 时，两种量化方法的 DROO 算法都不会收敛。这是因为当没有动作选择时，DNN 无法改进其卸载策略。&lt;/p&gt;
&lt;p&gt;总之，仿真结果表明所提出的 DROO 框架的有效性可以快速收敛到最优卸载策略，尤其是当使用所提出的保序动作量化方法时。&lt;/p&gt;
&lt;h3 id=&#34;更新间隔的影响-&#34;&gt;更新间隔的影响 ∆&lt;/h3&gt;
&lt;p&gt;DROO 算法只有在设置足够大的 Δ 时才收敛到最优解，例如 Δ ≥ 16。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507180631932.png&#34; alt=&#34;image-20230507180631932&#34;&gt;&lt;/p&gt;
&lt;p&gt;当 t 很大时，K~t~ 随 Δ 增加。这表明设置较大的 Δ 将导致更高的计算复杂度，即需要在一个时间范围内计算 (P2) 更多次。因此，在设置 Δ 时存在性能复杂性权衡。&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507180557914.png&#34; alt=&#34;image-20230507180557914&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;为了正确选择更新间隔 Δ，实验进行了10000 个通道实现的总 CPU 时间与最后一个时间帧中 $\hat{Q}$ 的移动平均值之间的权衡。一方面，我们看到当 ∆ ≤ 16 时，$\hat{Q}$的平均值从 0.96 迅速增加到接近 1，而当我们进一步增加 ∆ 时，改进变得微不足道。另一方面，CPU 时间随 Δ 单调增加。为了在性能和复杂性之间取得平衡，本文的DROO 算法设置∆ = 32。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507181011236.png&#34; alt=&#34;image-20230507181011236&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;计算速率性能&#34;&gt;计算速率性能&lt;/h3&gt;
&lt;p&gt;DROO 算法与三个具有代表性的基准进行比较：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Coordinate Descent (CD) algorithm：坐标下降算法。CD 算法在每一轮中迭代交换 WD 的计算模式，从而导致最大的计算率改进。也就是说，从 x~i~ = 0 到 x~i~ = 1，反之亦然。当不能通过计算模式交换进一步提高计算性能时，迭代停止。&lt;/li&gt;
&lt;li&gt;Local Computing：本地计算。所有N个WD只进行局部计算，即设x~i~ = 0，i = 1，····，N（P2中的N）。&lt;/li&gt;
&lt;li&gt;Edge Computing：边缘计算。所有 N 个 WD 都将它们的任务卸载到 AP，即设置 x~i~ = 1，i = 1，····，N（P2中的N）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下图，DROO 与 CD 方法实现了类似的近乎最优的性能，并且明显优于边缘计算和本地计算算法。&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507175851143.png&#34; alt=&#34;image-20230507175851143&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;h3 id=&#34;算法复杂度&#34;&gt;算法复杂度&lt;/h3&gt;
&lt;p&gt;DROO 实现了与 CD 算法相似的速率性能，但需要的 CPU 时间却少得多。&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230507180122041.png&#34; alt=&#34;image-20230507180122041&#34; style=&#34;zoom:50%;&#34; /&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://famousli.cn/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" term="论文笔记" label="论文笔记" />
                            
                        
                    
                
                    
                
            
        </entry>
    
        <entry>
            <title type="text">计算卸载|论文阅读笔记（一）</title>
            <link rel="alternate" type="text/html" href="https://famousli.cn/notes/mecnote1/" />
            <id>https://famousli.cn/notes/mecnote1/</id>
            <updated>2023-06-17T19:26:29&#43;08:00</updated>
            <published>2023-06-17T19:00:14&#43;08:00</published>
            <author>
                    <name>李清华</name>
                    <uri>https://famousli.cn/</uri>
                    <email>famousli2799@gmail.com</email>
                    </author>
            <summary type="html">标题：BeCome: Blockchain-Enabled Computation Offloading for IoT in Mobile Edge Computing（BeCome：移动边缘计算中……</summary>
            
                <content type="html">&lt;p&gt;标题：BeCome: Blockchain-Enabled Computation Offloading for IoT in Mobile Edge Computing（BeCome：移动边缘计算中物联网的区块链计算卸载）&lt;/p&gt;
&lt;p&gt;年份：2019&lt;/p&gt;
&lt;p&gt;期刊：IEEE Transactions on Industrial Informatics&lt;/p&gt;
&lt;p&gt;摘要：本文提出了一种名为 BeCome 的支持区块链的计算卸载方法。边缘计算采用区块链技术来确保数据完整性。采用非支配排序遗传算法 III (NSGA-III) 生成均衡资源分配策略。此外，使用简单加法加权 (SAW) 和多准则决策 (MCDM) 用于确定最佳卸载策略。&lt;/p&gt;
&lt;h2 id=&#34;主要贡献&#34;&gt;主要贡献&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;本文提出了一种名为 BeCome 的支持区块链的计算卸载方法&lt;/li&gt;
&lt;li&gt;采用&lt;strong&gt;非支配排序遗传算法 III (NSGA-III)&lt;/strong&gt; 生成均衡资源分配策略&lt;/li&gt;
&lt;li&gt;采用简单加法加权（SAW）和多准则决策（MCDM）技术确定基于虚拟机迁移技术的最优方案。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;数学模型&#34;&gt;数学模型&lt;/h2&gt;
&lt;h3 id=&#34;资源模型&#34;&gt;资源模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;假设有 Z 种 ECD，表示为 EC = {ec~1~, ec~2~, . . . , ec~Z~ }， ec~z~(z = {1, 2, · · · , Z}) 有 S 个数据发送器，记为 DT~z~ = {dt~z,1~, dt~z,2~, . . . , dt~z,S~}。第 z 种 ECD 的数量设置为 N ，表示为 C~z~= {c~z,1~, c~z,2~, . . . , c~z,N~}。&lt;/li&gt;
&lt;li&gt;假设物联网中有 M 个智能设备，假设智能设备只能执行一项任务。第m（m = {1, 2, . . ., M }）台智能设备的计算任务记为k~m~。&lt;/li&gt;
&lt;li&gt;通常，VM技术在物联网中的ECD资源管理方面功能强大，物理资源以VM实例的形式提供。ec~z~中第n个ECD（n = {1, 2, . . . , N }）的容量用VM实例的数量来衡量，表示为va~z,n~。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;定义 1（k~m~ 的资源需求）：&lt;/strong&gt; k~m~的资源需求由一个4元组定义，表示为r~m~ = (c~z~, nv~m~, st~m~, ft~m~)。其中c~z~、nv~m~、st~m~和ft~m~是k~m~使用的ECD类型、k~m~需要的VM数量、k~m~占用的开始时间和k~m~结束时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;时间消耗模型&#34;&gt;时间消耗模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;卸载时间模型&lt;/li&gt;
&lt;li&gt;任务排队时间模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;卸载方法&#34;&gt;卸载方法&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在区块链中使用分类账进行 ECD 资源监控&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;监控移动边缘计算中物联网的 ECD 和未占用 VM 实例的资源利用率&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;定义 2（VM 分配分类账）&lt;/strong&gt;：&lt;strong&gt;c~z,n~&lt;/strong&gt; 的分配账本记为 &lt;strong&gt;vat~z,n~&lt;/strong&gt;，用于记录**c~z,n~**收到卸载请求时的 VM 分配情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 NSGA-III 基于 VM 迁移的分配&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NSGA-III 快速执行全局搜索并保证质量。变异操作还允许算法更快地收敛。考虑到本文的目的是解决多目标优化问题，与传统的遗传算法相比，NSGA-III更有效地找到合适的解决方案。&lt;/li&gt;
&lt;li&gt;计算卸载策略由基因表示，适应度函数分为三类：时间消耗、能量消耗和负载平衡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 SAW 和 MCDM 进行迁移确认&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;根据种群中各目标函数值的最大值和最小值，首先对三个目标函数进行归一化&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预先确定适应度函数的权重以评估解的效用值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第b条染色体的效用值记为：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/image-20230504165233194.png&#34; alt=&#34;image-20230504165233194&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择具有最高效用值的最优策略作为最优策略&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://famousli.cn/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" term="论文笔记" label="论文笔记" />
                            
                        
                    
                
                    
                
            
        </entry>
    
        <entry>
            <title type="text">DDPG算法</title>
            <link rel="alternate" type="text/html" href="https://famousli.cn/notes/drl-ddpg/" />
            <id>https://famousli.cn/notes/drl-ddpg/</id>
            <updated>2023-06-17T19:50:19&#43;08:00</updated>
            <published>2023-06-17T16:52:04&#43;08:00</published>
            <author>
                    <name>李清华</name>
                    <uri>https://famousli.cn/</uri>
                    <email>famousli2799@gmail.com</email>
                    </author>
            <summary type="html">DDPG算法 DDPG算法一共包含了四个网络，分别是：Actor网络，Actor目标网……</summary>
            
                <content type="html">&lt;h1 id=&#34;ddpg算法&#34;&gt;DDPG算法&lt;/h1&gt;
&lt;p&gt;DDPG算法一共包含了四个网络，分别是：Actor网络，Actor目标网络，Critic网络，Critic目标网络，2个Actor 网络的结构相同，2个Critic网络的结构相同，四个网络的功能如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Actor网络：负责策略网络参数 $\theta$ 的迭代更新，负责根据当前状态 S 选择当前动作 A，用于和环境交互生成 S&#39; 和 R。&lt;/li&gt;
&lt;li&gt;Actor目标网络：负责根据经验回放池中采样的下一状态 S&#39; 选择最优下一动作 A&#39;，网络参数 $\theta&#39;$ 定期从 $\theta$ 中更新。&lt;/li&gt;
&lt;li&gt;Critic网络：负责价值网络参数 $w$ 的迭代更新，负责计算当前Q值 $Q(S,A,w)$。&lt;/li&gt;
&lt;li&gt;Critic目标网络：负责计算目标Q值 $y_i=R+\gamma Q&#39;(S&#39;,A&#39;,w&#39;)$ 中的 $Q&#39;(S&#39;,A&#39;,w&#39;)$ 部分，网络参数 $w&#39;$ 定期从  $w$ 更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ddpg算法流程&#34;&gt;DDPG算法流程&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;先初始化 Actor 和 Critic。然后把 Actor 和 Critic 的网络参数复制到目标 Actor 和目标 Critic 网络。&lt;/li&gt;
&lt;li&gt;将网络环境状态 S 输入 Actor网络得到动作 A，对环境施加动作 A，环境返回下一时刻的状态 S&#39; 以及奖励 R。并将这个四元组 $（S,A,R,S&#39;）$ 存入经验池。&lt;/li&gt;
&lt;li&gt;Critic 网络的更新。在经验池中积累一定数量的数据后，取出 mini-batch 大小的数据块，输入到 Critic 网络中，得到动作价值函数$Q(S,A,w)$。再将下一时刻状态 S&#39; 、动作 A&#39; 和上一时刻的奖励 R 一起输入目标 Critic 网络中，得到目标 Critic 网络的$Q_{target}=R+Q&#39;(S&#39;,A&#39;)$。Critic作为评委，一开始也不知道 Actor 输出的动作是否足够好，它也需要一步一步学习给出准确的打分，所以借助于目标网络拟合的下一时刻的价值 $Q&#39;$ ，以及真实的收益 $R$，我们可以得到 $Q_{target}$，让$Q_{target}$减去当前$Q$求均方差构造出Loss，再进行梯度下降来更新 Critic 网络参数。&lt;/li&gt;
&lt;li&gt;Actor 网络的更新。Actor的目标是找到最优动作 A 使得动作价值 Q 输出最大。因此，将通过将状态 S 以及 Actor 网络输出的动作 A 传入给 Critic 得到的结果$Q(S,A,w)$前面加负号作为损失函数，之后对其进行梯度下降进而实现 Actor 网络参数的更新。&lt;/li&gt;
&lt;li&gt;目标 Actor 网络和目标 Critic 网络的更新。我们每隔一段时间就把 Actor 网络和 Critic 网络的参数，拿去进行软更新目标 Actor网络和目标Critic 网络。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：两个Critic 网络的输入不同。Critic 网络中，动作和状态需要一起输入到 Critic 中；Critic 目标网络中，需要将动作、状态以及上一时刻的奖励一起输入Critic 目标网络。&lt;/p&gt;
&lt;img src=&#34;https://llc-typora.oss-cn-hangzhou.aliyuncs.com/typora/81be15e678ee87da6e19b066d0dcb34.jpg&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;h1 id=&#34;ddpg关键技术&#34;&gt;DDPG关键技术&lt;/h1&gt;
&lt;p&gt;DDPG算法主要包括以下三个关键技术：&lt;/p&gt;
&lt;p&gt;（1）经验回放：智能体将得到的经验数据放入 Memory Pool 中，更新网络参数时按照批量采样。&lt;/p&gt;
&lt;p&gt;（2）目标网络：在 Actor 网络和 Critic 网络外再使用一套用于估计目标的Target Actor网络和Target Critic网络。在更新目标网络时，为了避免参数更新过快，采用软更新方式。&lt;/p&gt;
&lt;p&gt;（3）噪声探索：确定性策略输出的动作为确定性动作，缺乏对环境的探索。在训练阶段，给Actor网络输出的动作加入噪声，从而让智能体具备一定的探索能力。&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/398288352&#34;&gt;强化学习入门——深入理解DDPG&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://juejin.cn/post/6869355403637964813&#34;&gt;强化学习13——Deep Deterministic Policy Gradient（DDPG）原理与实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_46133643/article/details/124356983&#34;&gt;深度强化学习-DDPG算法原理与代码&lt;/a&gt;&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                        
                            
                            
                            
                                <category scheme="https://famousli.cn/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" term="强化学习" label="强化学习" />
                            
                        
                    
                
                    
                
            
        </entry>
    
</feed>
